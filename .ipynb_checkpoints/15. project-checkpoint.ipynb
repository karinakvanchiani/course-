{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подход 1: градиентный бустинг \"в лоб\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.read_csv('C:\\\\Users\\\\kvanc\\\\coursera\\\\files\\\\features.csv', index_col = 'match_id')\n",
    "features_test = pd.read_csv('C:\\\\Users\\\\kvanc\\\\coursera\\\\files\\\\features_test.csv', index_col = 'match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = features_train['radiant_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = features_train.columns.difference(features_test.columns.values.tolist()).tolist()\n",
    "features_train.drop(difference, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time\n",
      "first_blood_team\n",
      "first_blood_player1\n",
      "first_blood_player2\n",
      "radiant_bottle_time\n",
      "radiant_courier_time\n",
      "radiant_flying_courier_time\n",
      "radiant_first_ward_time\n",
      "dire_bottle_time\n",
      "dire_courier_time\n",
      "dire_flying_courier_time\n",
      "dire_first_ward_time\n",
      "all_skips =  193087\n"
     ]
    }
   ],
   "source": [
    "skips = {}\n",
    "for i in range(102):\n",
    "    if features_train.iloc[:, i].count() != 97230:\n",
    "        s = 97230 - features_train.iloc[:, i].count()\n",
    "        skips[i] = s\n",
    "all_skips = 0\n",
    "for key, value in skips.items():\n",
    "    all_skips += value\n",
    "    print(features_train.columns.values[key])\n",
    "print('all_skips = ', all_skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.ix[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0:00:11.337704\n",
      "time elapsed: 0:00:20.638656\n",
      "time elapsed: 0:00:29.872240\n",
      "time elapsed: 0:00:58.994814\n",
      "time elapsed: 0:01:08.818893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{10: 0.66483292280491,\n",
       " 20: 0.6821140369500348,\n",
       " 30: 0.6896947542059906,\n",
       " 60: 0.6998001572455899,\n",
       " 70: 0.7018939073914252}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "scores = {}\n",
    "for i in [10, 20, 30, 60, 70]:\n",
    "    clf = GradientBoostingClassifier(n_estimators = i, random_state = 241)\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf.fit(X, target_train)\n",
    "    print('time elapsed:', datetime.datetime.now() - start_time)\n",
    "    score = cross_val_score(clf, X, target_train, scoring = 'roc_auc', cv = kf)\n",
    "    scores[i] = score.mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0:02:01.193987\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators = 30, random_state = 241)\n",
    "clf.fit(X, target_train)\n",
    "start_time = datetime.datetime.now()\n",
    "score = cross_val_score(clf, X, target_train, scoring = 'roc_auc', cv = kf).mean()\n",
    "print('time elapsed:', datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подход 2: логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_scores(X, target):\n",
    "    C_list = list(np.power(10.0, np.arange(-3, 3)))\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    scores = {}\n",
    "    for C in C_list:\n",
    "        clf = LogisticRegression(penalty = 'l2', C = C)\n",
    "        start_time = datetime.datetime.now()\n",
    "        score = cross_val_score(clf, scaler.transform(X), target, scoring = 'roc_auc', cv = kf)\n",
    "        print('time elapsed:', datetime.datetime.now() - start_time)\n",
    "        scores[C] = score.mean()\n",
    "    best_score = 0\n",
    "    for key, value in scores.items():\n",
    "        if value > best_score:\n",
    "            best_score = value\n",
    "            best_C = key\n",
    "    return best_C, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_scores_2(X, target):\n",
    "    C_list = list(np.power(10.0, np.arange(-3, 3)))\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    scores = {}\n",
    "    for C in C_list:\n",
    "        clf = LogisticRegression(penalty = 'l2', C = C)\n",
    "        start_time = datetime.datetime.now()\n",
    "        score = cross_val_score(clf, X, target, scoring = 'roc_auc', cv = kf)\n",
    "        print('time elapsed:', datetime.datetime.now() - start_time)\n",
    "        scores[C] = score.mean()\n",
    "    best_score = 0\n",
    "    for key, value in scores.items():\n",
    "        if value > best_score:\n",
    "            best_score = value\n",
    "            best_C = key\n",
    "    return best_C, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0:00:15.574311\n",
      "time elapsed: 0:00:20.291152\n",
      "time elapsed: 0:00:21.234645\n",
      "time elapsed: 0:00:21.195530\n",
      "time elapsed: 0:00:21.139779\n",
      "time elapsed: 0:00:21.198743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01, 0.7163757959125769)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scores(X, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = pd.read_csv('C:\\\\Users\\\\kvanc\\\\coursera\\\\files\\\\features.csv', index_col = 'match_id')\n",
    "new_features.drop(difference, axis = 1, inplace = True)\n",
    "new_features = new_features.fillna(0)\n",
    "new_features.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero',\n",
    "                   'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = new_features.ix[:, :]\n",
    "scaler = StandardScaler().fit(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0:00:13.743888\n",
      "time elapsed: 0:00:18.488458\n",
      "time elapsed: 0:00:19.482043\n",
      "time elapsed: 0:00:19.631830\n",
      "time elapsed: 0:00:19.481848\n",
      "time elapsed: 0:00:19.451461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01, 0.7164088702736156)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scores(new_X, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = pd.Series()\n",
    "for h in ['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']:\n",
    "    heroes = heroes.append(features[h])\n",
    "N = heroes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pick = np.zeros((features.shape[0], N))\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, features.ix[match_id, 'r%d_hero' % (p + 1)] - 1] = 1\n",
    "        X_pick[i, features.ix[match_id, 'd%d_hero' % (p + 1)] - 1] = -1\n",
    "X_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97230, 112)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pick.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0:00:16.344432\n",
      "time elapsed: 0:00:26.828072\n",
      "time elapsed: 0:00:37.747380\n",
      "time elapsed: 0:00:39.623838\n",
      "time elapsed: 0:00:39.105853\n",
      "time elapsed: 0:00:38.805176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1, 0.7518731057809973)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scores_2(np.hstack([scaler.transform(new_X), X_pick]), target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test.fillna(0, inplace=True)\n",
    "X_pick_test = np.zeros((features_test.shape[0], N))\n",
    "for i, match_id in enumerate(features_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick_test[i, features_test.ix[match_id, 'r%d_hero' % (p + 1)] - 1] = 1\n",
    "        X_pick_test[i, features_test.ix[match_id, 'd%d_hero' % (p + 1)] - 1] = -1\n",
    "features_test.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                    'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1, inplace=True)\n",
    "scaler = StandardScaler().fit(new_features)\n",
    "X_test = features_test.ix[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 0.1)\n",
    "clf.fit(np.hstack([scaler.transform(new_features), X_pick]), target_train)\n",
    "scaler = StandardScaler().fit(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict_proba(np.hstack((scaler.transform(features_test), X_pick_test)))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008580592559245393 0.9964586771296121\n"
     ]
    }
   ],
   "source": [
    "print(min(pred), max(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
